## __TL;DR__
Morpheus is supposed to facilitate the hookups of users with compute providers to run LLM prompts, of which some prompts will execute Web3 actions. This is Limewire, but for LLMs. There exists no safeguards to actually ensure that the compute provider is running an LLM to begin with, the token distribution system has holes, there is no prompt security (your prompts will be known to the compute provider) and the project is very confused as to what it wants to be.

## __First Blush__

The separation between Smart Agents and Morpheus as products does not exist, and thus lends skepticism to why it is that Morpheus was proposed by some anonymous creators to leverage the "Smart Agent framework".

It seems like "working versions" of the local LLM are up for grabs on the Morpheus GitHub page (why do they not exist on the Smart Agent GitHub?), so this can be looked into later.

## [__Whitepaper__](https://github.com/MorpheusAIs/Docs/blob/main/!KEYDOCS%20README%20FIRST!/WhitePaper.md)

(Personal opinion: I think the Matrix marketing stuff is a bit stupid and cringe.)

- Quote: "To make Smart Agents accessible to everyone and increase decentralization of their infrastructure, we propose the development of the Morpheus network. The Morpheus network will include a fairly launched token (the "MOR" token) for incentivizing all four of the key contributors to the network."
- The four in question:
	- "Community of builders creating interfaces"
	- MOR devs contributing to agents
	- Capital providers (LP)
	- Supplying computation, storage and bandwidth (how?)

We've previously established that the Smart Agent is a local LLM, so it makes things a bit confusing from the get go. Do they have some system to run the LLM in a decentralized manner? (no, they don't).

- Quote: "What these open-source LLMs currently lack is a standard graphical interface by which users can chat with them, an API for developers, a cloud solution to move between devices and a way to manage user data and the recovery process. This is where the Smart Agent Protocol comes in, as it provides an open-source LLM run locally and is managed by a user's Web3 wallet."
	- This point can be very easily refuted with the large number of GUIs and E2E solutions for running local LLMs, especially Llama

- Quote: "However, the local only approach still lacks an API for developers to build on and the cloud solution where a network of users can run the software on powerful hardware to enable use cases such as light clients, where the user doesn't need to download the full node or Smart Agent locally."
- Quote: "Running on the decentralized public infrastructure is cheaper than paying Chat GPT a license fee for every new user."

- Token Distribution
	- 24% goes to compute, "proof of transactions for API calls served"
	- 24% goes to coders based on their merged commits to the main repo
	- 24% goes to capital. Quote: "Proof of stETH yield contributed, 50% swapped for MOR & paired with the rest 50% to lock in the AMM as a Protocol-owned Liquidity (PoL)."
	- 24% goes to community. Quote: "Proof of building front end applications & tools that engage users."

  - MOR will be used to pay for compute, pay for API calls to LLMs and pay for... training data?
  - Compute flow goes a little like this:
	  - User holds MOR, requests for compute, this request is sent to a Router
	  - Router matches up the User with a Compute provider
		- This is done through the "lowest Bid per IPS in MOR"
	- Prompt is sent to the provider, response is generated by LLM and sent back (does not go through router)
		- Compute providers also need to hold MOR to "discourage Sybil attack"
	- "User reports success metrics to Router" and compute is rewarded MOR via the compute contract based on this

So far, it sounds like a gameable system, and if not, one that is very subjective. Rewards are determined by loose metrics, and the system which enables "decentralized prompting" is just a system that hooks up users and folk running LLMs. There also appears to be no checks in place that you're actually interacting with an LLM. 

Quote: "Providers should need to prove they have a given LLM, by signing hash of LLM model with their key." 

This implementation needs to be investigated, hopefully it is addressed in the yellowpaper.

## [__Yellowpaper__](https://github.com/MorpheusAIs/Docs/blob/main/!KEYDOCS%20README%20FIRST!/YellowPaper.md) 

Quote: "Audits of Agents performed by Coders generating an "Agent Proof" that the stated functions of the Agent are as presented. And of course contains no malicious code.

Placeholder for description of audit process, who can conduct audits and how to certify their outcomes. Also incentives paid to auditors.

Prompt Proof generated at the time of a user interaction showing the intent expressed, matches the smart contract selection and transaction values are confirmed with the user."

Not very promising. The details we were looking for haven't even been written out. Again, the rest of the technical details are quite vague.

An obvious issue is the security of prompts --- even if it is a decentralized system, we still want our prompts to remain private and the responses as well. The team proposes Fully Homomorphic Encryption (FHE) LLMs, but they are 1) not a thing yet beyond toy examples and 2) definitely are not currently implemented.


## [__Yellowstone Compute Model__](https://github.com/MorpheusAIs/Docs/blob/main/!KEYDOCS%20README%20FIRST!/Yellowstone%20Compute%20Model.md)

This document was (supposedly) written by [Erik Voorhees](https://twitter.com/ErikVoorhees), ShapeShift's founder. He has [spoken](https://www.youtube.com/watch?v=Pi6Qso1WHJQ) about the project and is apparently a [community member](https://thedefiant.io/news/defi/morpheus-ai-launch-attracts-usd50m-within-hours). The [GitHub](https://github.com/ErikVoorhees) account used to commit these docs appears to have been made [just to add the doc](https://github.com/MorpheusAIs/Morpheus/commit/0317410449677eff71fca68e7ff63089caa0e7e8) and otherwise has had no activity. Personally, I think it's suspect, but we can grant the benefit of the doubt.

This document appears to lend further detail to the compute workflow described in the whitepaper and yellowpaper. Here are some highlights:

- AccessRate: the number of prompts and IPS (inferences per second) you're allowed daily is based on how much MOR you hold. 

- Quote: "Providers should need to prove they have a given LLM, by signing hash of LLM model with their key. This doesn’t prove they used it, but it proves they downloaded and installed it, which represents work, thus preventing some forms of sybil-sensitive fraud."
	- This more or less lines up with what has been mentioned earlier: there is no way to tell if you're being gamed and there actually is an LLM being prompted here.
	
- Quote: "If Providers provide garbage results to User, User can send \[Fail] along with \[milliseconds] back to Router, and Provider won’t be credited for that compute."
	- Then can I not cause network congestion by simply failing a bunch of providers?
	- This is addressed, quote: "Sybil attacks \[via flooding are prevented by AccessRate]", yet it's not a particularly strong argument. 
	
- Quote: "Morpheus doesn’t need all answers to be perfect… it only needs enough answers to be good enough, relative to competing alternatives... Pass/Fail is determined by User, and polices quality to some degree. User conveys Pass/Fail result alongside \[milliseconds] back to Router. If Fail, either no reward or penalty point (TBD). There is no incentive to falsely Fail a Provider (no monetary incentive in doing so)."
	- Again, marks of a somewhat clunky system.


